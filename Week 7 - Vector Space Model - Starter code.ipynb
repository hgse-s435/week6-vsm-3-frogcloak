{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 - Vector Space Model (VSM) and Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the next weeks, we are going to re-implement Sherin's algorithm and apply it to the text data we've been working on last week! Here's our roadmap:\n",
    "\n",
    "**Week 6 - vectorization and linear algebra**\n",
    "6. Dampen: weight the frequency of words (1 + log[count])\n",
    "7. Scale: Normalize weighted frequency of words\n",
    "8. Direction: compute deviation vectors\n",
    "\n",
    "**Week 7 - Clustering**\n",
    "9. apply different unsupervised machine learning algorithms\n",
    "    * figure out how many clusters we want to keep\n",
    "    * inspect the results of the clustering algorithm\n",
    "\n",
    "**Week 8 - Visualizing the results**\n",
    "10. create visualizations to compare documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 5 - DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:32.900015Z",
     "start_time": "2019-05-10T16:06:32.895790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Papers/paper12.txt', './Papers/paper5.txt', './Papers/paper4.txt', './Papers/paper13.txt', './Papers/paper11.txt', './Papers/paper6.txt', './Papers/paper7.txt', './Papers/paper10.txt', './Papers/paper14.txt', './Papers/paper3.txt', './Papers/paper2.txt', './Papers/paper15.txt', './Papers/paper0.txt', './Papers/paper1.txt', './Papers/paper16.txt', './Papers/paper9.txt', './Papers/paper8.txt']\n"
     ]
    }
   ],
   "source": [
    "# using glob, find all the text files in the \"Papers\" folder\n",
    "import glob\n",
    "\n",
    "files = glob.glob('./Papers/*.txt')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:34.384573Z",
     "start_time": "2019-05-10T16:06:34.371421Z"
    }
   },
   "outputs": [],
   "source": [
    "# get all the data from the text files into the \"documents\" list\n",
    "# P.S. make sure you use the 'utf-8' encoding\n",
    "documents = []\n",
    "\n",
    "for filename in files: \n",
    "    with open (filename, \"r\", encoding='utf-8') as f:\n",
    "        documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:35.262840Z",
     "start_time": "2019-05-10T16:06:35.253353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'103\\n\\n\\x0cepistemic network analysis and topic modeling for chat\\ndata from collaborative learning environment\\nzhiqiang cai\\n\\nbrendan eagan\\n\\nnia m. dowell\\n\\nthe university of memphis\\n365 innovation drive, suite 410\\nmemphis, tn, usa\\n\\nuniversity of wisconsin-madison\\n1025 west johnson street\\nmadison, wi, usa\\n\\nthe university of memphis\\n365 innovation drive, suite 410\\nmemphis, tn, usa\\n\\nzcai@memphis.edu\\n\\neaganb@gmail.com\\n\\nniadowell@gmail.com\\n\\njames w. pennebaker\\n\\ndavid w. shaffer\\n\\narthur c. graesser\\n\\nuniversity of texas-austin\\n116 inner campus dr stop g6000\\naustin, tx, usa\\n\\nuniversity of wisconsin-madison\\n1025 west johnson street\\nmadison, wi, usa\\n\\nthe university of memphis\\n365 innovation drive, suite 403\\nmemphis, tn, usa\\n\\npennebaker@utexas.edu\\n\\ndws@education.wisc.edu\\n\\nart.graesser@gmail.com\\n\\nabstract\\nthis study investigates a possible way to analyze chat data from\\ncollaborative learning environments using epistemic network\\nanalysis and topic modeling. a 300-topic general topic model\\nbuilt from tasa (touchstone applied science associates) corpus was used in this study. 300 topic scores for each of the 15,670\\nutterances in our chat data were computed. seven relevant topics\\nwere selected based on the total document scores. while the aggregated topic scores had some power in predicting students‚Äô\\nlearning, using epistemic network analysis enables assessing the\\ndata from a different angle. the results showed that the topic\\nscore based epistemic networks between low gain students and\\nhigh gain s'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 1000 characters of the first document to see what it \n",
    "# looks like (we'll use this as a sanity check below)\n",
    "documents[0][:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:36.995694Z",
     "start_time": "2019-05-10T16:06:36.989843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40387 34778\n",
      "37214 32762\n",
      "44037 40032\n",
      "45258 42251\n",
      "32277 28206\n",
      "47851 41302\n",
      "42617 35102\n",
      "49177 42621\n",
      "40655 32734\n",
      "47377 42978\n",
      "46761 42253\n",
      "31574 28134\n",
      "50043 39318\n",
      "41110 35514\n",
      "42046 37649\n",
      "47845 44059\n",
      "45724 39947\n"
     ]
    }
   ],
   "source": [
    "# only select the text that's between the first occurence of the \n",
    "# the word \"abstract\" and the last occurence of the word \"reference\"\n",
    "# Optional: print the length of the string before and after, as a \n",
    "# sanity check\n",
    "# HINT: https://stackoverflow.com/questions/14496006/finding-last-occurrence-of-substring-in-string-replacing-that\n",
    "# read more about rfind: https://www.tutorialspoint.com/python/string_rfind.htm\n",
    "\n",
    "for i,doc in enumerate(documents):\n",
    "    print(len(documents[i]), end=' ')\n",
    "    # only keep the text after the abstract\n",
    "    doc = doc[doc.index('abstract'):doc.rfind('reference')]\n",
    "    # save the result\n",
    "    documents[i] = doc\n",
    "    # print the length of the resulting string\n",
    "    print(len(documents[i]))\n",
    "    \n",
    "# one liner:\n",
    "# documents = [doc[doc.index('abstract'):doc.rfind('reference')] for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:38.569309Z",
     "start_time": "2019-05-10T16:06:38.564385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract this study investigates a possible way to analyze chat data from collaborative learning environments using epistemic network analysis and topic modeling. a 300-topic general topic model built from tasa (touchstone applied science associates) corpus was used in this study. 300 topic scores for each of the 15,670 utterances in our chat data were computed. seven relevant topics were selected based on the total document scores. while the aggregated topic scores had some power in predicting students‚Äô learning, using epistemic network analysis enables assessing the data from a different angle. the results showed that the topic score based epistemic networks between low gain students and high gain students were significantly different (ùë° = 2.00). overall, the results suggest these two analytical approaches provide complementary information and afford new insights into the processes related to successful collaborative interactions.  keywords chat; collaborative learning; topic modelin\n"
     ]
    }
   ],
   "source": [
    "# replace carriage returns (i.e., \"\\n\") with a white space\n",
    "# check that the result looks okay by printing the \n",
    "# first 1000 characters of the 1st doc:\n",
    "\n",
    "documents = [doc.replace('\\n', ' ') for doc in documents]\n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:39.238916Z",
     "start_time": "2019-05-10T16:06:39.228075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract this study investigates a possible way to analyze chat data from collaborative learning environments using epistemic network analysis and topic modeling  a 300 topic general topic model built from tasa  touchstone applied science associates  corpus was used in this study  300 topic scores for each of the 15 670 utterances in our chat data were computed  seven relevant topics were selected based on the total document scores  while the aggregated topic scores had some power in predicting students  learning  using epistemic network analysis enables assessing the data from a different angle  the results showed that the topic score based epistemic networks between low gain students and high gain students were significantly different  ùë°   2 00   overall  the results suggest these two analytical approaches provide complementary information and afford new insights into the processes related to successful collaborative interactions   keywords chat  collaborative learning  topic modelin\n"
     ]
    }
   ],
   "source": [
    "# replace the punctation below by a white space\n",
    "# check that the result looks okay \n",
    "# (e.g., by print the first 1000 characters of the 1st doc)\n",
    "\n",
    "punctuation = ['.', '...', '!', '#', '\"', '%', '$', \"'\", '&', ')', \n",
    "               '(', '+', '*', '-', ',', '/', '.', ';', ':', '=', \n",
    "               '<', '?', '>', '@', '\",', '\".', '[', ']', '\\\\', ',',\n",
    "               '_', '^', '`', '{', '}', '|', '~', '‚àí', '‚Äù', '‚Äú', '‚Äô']\n",
    "\n",
    "\n",
    "# remove ponctuation\n",
    "for i,doc in enumerate(documents): \n",
    "    for punc in punctuation: \n",
    "        doc = doc.replace(punc, ' ')\n",
    "    documents[i] = doc\n",
    "    \n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:40.096421Z",
     "start_time": "2019-05-10T16:06:40.088417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract there is a critical need to develop new educational technology applications that analyze the data collected by universities to ensure that students graduate in a timely fashion   to  years   and they are well prepared for jobs in their respective fields of study  in this paper  we present a novel approach for analyzing historical educational records from a large  public university to perform next term grade prediction  i e   to estimate the grades that a student will get in a course that he she will enroll in the next term  accurate next term grade prediction holds the promise for better student degree planning  personalized advising and automated interventions to ensure that students stay on track in their chosen degree program and graduate on time  we present a factorization based approach called matrix factorization with temporal course wise influence that incorporates course wise influence effects and temporal effects for grade prediction  in this model  students and cours\n"
     ]
    }
   ],
   "source": [
    "# remove numbers by either a white space or the word \"number\"\n",
    "# again, print the first 1000 characters of the first document\n",
    "# to check that you're doing the right thing\n",
    "for i,doc in enumerate(documents): \n",
    "    for num in range(10):\n",
    "        doc = doc.replace(str(num), '')\n",
    "    documents[i] = doc\n",
    "\n",
    "print(documents[1][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:40.821817Z",
     "start_time": "2019-05-10T16:06:40.684952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract study investigates possible way analyze chat data collaborative learning environments using epistemic network analysis topic modeling   topic general topic model built tasa  touchstone applied science associates  corpus used study   topic scores   utterances chat data computed  seven relevant topics selected based total document scores  aggregated topic scores power predicting students  learning  using epistemic network analysis enables assessing data different angle  results showed topic score based epistemic networks low gain students high gain students significantly different  ùë°       overall  results suggest two analytical approaches provide complementary information afford new insights processes related successful collaborative interactions   keywords chat  collaborative learning  topic modeling  epistemic network analysis    introduction collaborative learning special form learning interaction affords opportunities groups students combine cognitive resources synchronousl\n"
     ]
    }
   ],
   "source": [
    "# Remove the stop words below from our documents\n",
    "# print the first 1000 characters of the first document\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "              'ourselves', 'you', 'your', 'yours', 'yourself', \n",
    "              'yourselves', 'he', 'him', 'his', 'himself', 'she', \n",
    "              'her', 'hers', 'herself', 'it', 'its', 'itself', \n",
    "              'they', 'them', 'their', 'theirs', 'themselves', \n",
    "              'what', 'which', 'who', 'whom', 'this', 'that', \n",
    "              'these', 'those', 'am', 'is', 'are', 'was', 'were', \n",
    "              'be', 'been', 'being', 'have', 'has', 'had', 'having', \n",
    "              'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', \n",
    "              'but', 'if', 'or', 'because', 'as', 'until', 'while', \n",
    "              'of', 'at', 'by', 'for', 'with', 'about', 'against', \n",
    "              'between', 'into', 'through', 'during', 'before', \n",
    "              'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "              'in', 'out', 'on', 'off', 'over', 'under', 'again', \n",
    "              'further', 'then', 'once', 'here', 'there', 'when', \n",
    "              'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "              'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "              'nor', 'not', 'only', 'own', 'same', 'so', 'than', \n",
    "              'too', 'very', 's', 't', 'can', 'will', \n",
    "              'just', 'don', 'should', 'now']\n",
    "\n",
    "\n",
    "# remove stop words\n",
    "for i,doc in enumerate(documents):\n",
    "    for stop_word in stop_words:\n",
    "        doc = doc.replace(' ' + stop_word + ' ', ' ')\n",
    "    documents[i] = doc\n",
    "\n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:41.248125Z",
     "start_time": "2019-05-10T16:06:41.233043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract study investigates possible way analyze chat data collaborative learning environments using epistemic network analysis topic modeling topic general topic model built tasa touchstone applied science associates corpus used study topic scores utterances chat data computed seven relevant topics selected based total document scores aggregated topic scores power predicting students learning using epistemic network analysis enables assessing data different angle results showed topic score based epistemic networks low gain students high gain students significantly different overall results suggest two analytical approaches provide complementary information afford new insights processes related successful collaborative interactions keywords chat collaborative learning topic modeling epistemic network analysis introduction collaborative learning special form learning interaction affords opportunities groups students combine cognitive resources synchronously asynchronously participate ta\n"
     ]
    }
   ],
   "source": [
    "# remove words with one and two characters (e.g., 'd', 'er', etc.)\n",
    "# print the first 1000 characters of the first document\n",
    "\n",
    "for i,doc in enumerate(documents):  \n",
    "    doc = [x for x in doc.split() if len(x) > 2]\n",
    "    doc = \" \".join(doc)\n",
    "    documents[i] = doc\n",
    "\n",
    "print(documents[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:42.462834Z",
     "start_time": "2019-05-10T16:06:42.458331Z"
    }
   },
   "outputs": [],
   "source": [
    "# package all of your work above into a function that cleans a given document\n",
    "\n",
    "def clean_list_of_documents(documents):\n",
    "    \n",
    "    cleaned_docs = []\n",
    "\n",
    "    for i,doc in enumerate(documents):\n",
    "        # only keep the text after the abstract\n",
    "        doc = doc[doc.index('abstract'):]\n",
    "        # only keep the text before the references\n",
    "        doc = doc[:doc.rfind('reference')]\n",
    "        # replace return carriage with white space\n",
    "        doc = doc.replace('\\n', ' ')\n",
    "        # remove ponctuation\n",
    "        for punc in punctuation: \n",
    "            doc = doc.replace(punc, ' ')\n",
    "        # remove numbers\n",
    "        for i in range(10):\n",
    "            doc = doc.replace(str(i), ' ')\n",
    "        # remove stop words\n",
    "        for stop_word in stop_words:\n",
    "            doc = doc.replace(' ' + stop_word + ' ', ' ')\n",
    "        # remove single characters and stem the words \n",
    "        doc = [x for x in doc.split() if len(x) > 2]\n",
    "        doc = \" \".join(doc)\n",
    "        # save the result to our list of documents\n",
    "        cleaned_docs.append(doc)\n",
    "        \n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:43.174352Z",
     "start_time": "2019-05-10T16:06:43.028963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract study investigates possible way analyze chat data collaborative learning environments using epistemic network analysis topic modeling topic general topic model built tasa touchstone applied science associates corpus used study topic scores utterances chat data computed seven relevant topics selected based total document scores aggregated topic scores power predicting students learning using epistemic network analysis enables assessing data different angle results showed topic score based epistemic networks low gain students high gain students significantly different overall results suggest two analytical approaches provide complementary information afford new insights processes related successful collaborative interactions keywords chat collaborative learning topic modeling epistemic network analysis introduction collaborative learning special form learning interaction affords opportunities groups students combine cognitive resources synchronously asynchronously participate ta\n"
     ]
    }
   ],
   "source": [
    "# reimport your raw data\n",
    "documents = []\n",
    "\n",
    "for filename in files: \n",
    "    with open (filename, \"r\", encoding='utf-8') as f:\n",
    "        documents.append(f.read())\n",
    "        \n",
    "# clean your files using the function above\n",
    "docs = clean_list_of_documents(documents)\n",
    "\n",
    "# print the first 1000 characters of the first document\n",
    "print(docs[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Build your list of vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of words (i.e., the vocabulary) is going to become the columns of your matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:44.539524Z",
     "start_time": "2019-05-10T16:06:44.537279Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:45.764106Z",
     "start_time": "2019-05-10T16:06:45.023648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5676\n"
     ]
    }
   ],
   "source": [
    "# create a function that takes in a list of documents\n",
    "# and returns a set of unique words. Make sure that you\n",
    "# sort the list alphabetically before returning it. \n",
    "\n",
    "def get_vocabulary(docs):\n",
    "    voc = []\n",
    "    for doc in docs:\n",
    "        for word in doc.split():\n",
    "            if word not in voc: \n",
    "                voc.append(word)\n",
    "    voc = list(set(voc))\n",
    "    voc.sort()\n",
    "    return voc\n",
    "\n",
    "# Then print the length of your vocabulary (it should be \n",
    "# around 5500 words)\n",
    "vocabulary = get_vocabulary(docs)\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - transform your documents in to 100-words chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:46.117731Z",
     "start_time": "2019-05-10T16:06:46.100965Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a function that takes in a list of documents\n",
    "# and returns a list of 100-words chunk \n",
    "# (with a 25 words overlap between them)\n",
    "# Optional: add two arguments, one for the number of words\n",
    "# in each chunk, and one for the overlap\n",
    "\n",
    "def flatten_and_overlap(docs, window_size=100, overlap=25):\n",
    "    \n",
    "    # create the list of overlapping documents\n",
    "    new_list_of_documents = []\n",
    "    \n",
    "    # flatten everything into one string\n",
    "    flat = \"\"\n",
    "    for doc in docs:\n",
    "        flat += doc\n",
    "    \n",
    "    # split into words\n",
    "    flat = flat.split()\n",
    "\n",
    "    # create chunks of 100 words\n",
    "    high = window_size\n",
    "    while high < len(flat):\n",
    "        low = high - window_size\n",
    "        new_list_of_documents.append(flat[low:high])\n",
    "        high += overlap\n",
    "    return new_list_of_documents\n",
    "\n",
    "chunks = flatten_and_overlap(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:46.756740Z",
     "start_time": "2019-05-10T16:06:46.754142Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a for loop to double check that each chunk has \n",
    "# a length of 100\n",
    "# Optional: use assert to do this check\n",
    "for chunk in chunks: \n",
    "    assert(len(chunk) == 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 6 - VECTOR MANIPULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Create a word by document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:06:48.956825Z",
     "start_time": "2019-05-10T16:06:48.315838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2219 entries, 0 to 2218\n",
      "Columns: 5676 entries, \u0000\u0010\u0000 to ùüéùüíùüï\n",
      "dtypes: int64(5676)\n",
      "memory usage: 96.1 MB\n"
     ]
    }
   ],
   "source": [
    "# 1) create an empty dataframe using pandas\n",
    "# the number of rows should be the number of chunks we have\n",
    "# the number of columns should be size of the vocabulary\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(0, index=np.arange(len(chunks)), columns=vocabulary)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:07:25.372423Z",
     "start_time": "2019-05-10T16:06:49.218383Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2) fill out the dataframe with the count of words for each document\n",
    "# (use two for loops to iterate through the documents and the vocabulary)\n",
    "for i,chunk in enumerate(chunks):\n",
    "    for word in chunk:\n",
    "        if word in df.columns: \n",
    "            df.loc[i,word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:07:25.765460Z",
     "start_time": "2019-05-10T16:07:25.762164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Sanity check: make sure that your counts are correct\n",
    "# (e.g., if you know that a words appears often in a document, check that\n",
    "# the number is also high in your dataframe; and vice-versa for low counts)\n",
    "df.loc[0,'wandering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:08:01.810306Z",
     "start_time": "2019-05-10T16:07:26.014832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Putting it together: create a function that takes a list of documents\n",
    "# and a vocabulary as arguments, and returns a dataframe with the counts\n",
    "# of words: \n",
    "def docs_by_words_df(chunks, vocabulary):\n",
    "    df = pd.DataFrame(0, index=np.arange(len(chunks)), columns=vocabulary)\n",
    "    \n",
    "    # fill out the matrix with counts\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        for word in chunk:\n",
    "            if word in df.columns: \n",
    "                df.loc[i,word] += 1\n",
    "            \n",
    "    return df\n",
    "\n",
    "# call the function and check that the resulting dataframe is correct\n",
    "df = docs_by_words_df(chunks, vocabulary)\n",
    "df.loc[0,'wandering']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Weight word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:08:38.830323Z",
     "start_time": "2019-05-10T16:08:38.827397Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5) create a function that adds one to the current cell and takes its log\n",
    "# IF the value in the cell is not zero\n",
    "def one_plus_log(cell):\n",
    "    if cell != 0: \n",
    "        return 1 + math.log(cell)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:08:43.553728Z",
     "start_time": "2019-05-10T16:08:39.540139Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6) use the \"applymap\" function of the dataframe to apply the function \n",
    "# above to each cell of the table\n",
    "df_log = df.applymap(one_plus_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:12.049354Z",
     "start_time": "2019-05-10T16:09:12.039700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before one + log:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-477de5973d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print the value before and after applying the function above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"before one + log: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wandering'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after one + log: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wandering'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Value in the dataframe: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wandering'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "# 7) check that the numbers in the resulting matrix look accurate;\n",
    "# print the value before and after applying the function above\n",
    "print(\"before one + log: \", df.loc[0,'wandering'])\n",
    "print(\"after one + log: \", 1 + math.log(df.loc[0,'wandering']))\n",
    "print(\"Value in the dataframe: \", df_log.loc[0,'wandering'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Matrix normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:16.510790Z",
     "start_time": "2019-05-10T16:09:16.508503Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8) look at the image below; why do you think that we need to normalize our \n",
    "# data before clustering in this particular case? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.stack.imgur.com/N2unM.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, it's common practice to normalize your data before clustering - so that variables are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T15:56:08.504688Z",
     "start_time": "2019-05-10T15:55:51.020Z"
    }
   },
   "outputs": [],
   "source": [
    "# 9) describe how the min-max normalization works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/media/aml-normalization-minmax.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T15:56:08.505522Z",
     "start_time": "2019-05-10T15:55:51.023Z"
    }
   },
   "outputs": [],
   "source": [
    "# 10) describe how normalizing using a z-score works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*13XKCXQc7eabfZbRzkvGvA.gif\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T15:56:08.506928Z",
     "start_time": "2019-05-10T15:55:51.026Z"
    }
   },
   "outputs": [],
   "source": [
    "# 11) describe how normalizing to unit norm works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources: \n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer\n",
    "* http://mathworld.wolfram.com/NormalVector.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with some pre-made normalization functions from sklearn (feel free to skim this page):\n",
    "* https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:29.862897Z",
     "start_time": "2019-05-10T16:09:27.406209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>become</th>\n",
       "      <th>becomes</th>\n",
       "      <th>becoming</th>\n",
       "      <th>been</th>\n",
       "      <th>beep</th>\n",
       "      <th>began</th>\n",
       "      <th>begin</th>\n",
       "      <th>beginning</th>\n",
       "      <th>begins</th>\n",
       "      <th>behave</th>\n",
       "      <th>...</th>\n",
       "      <th>boy</th>\n",
       "      <th>boyce</th>\n",
       "      <th>boyd</th>\n",
       "      <th>boys</th>\n",
       "      <th>brain</th>\n",
       "      <th>branch</th>\n",
       "      <th>branched</th>\n",
       "      <th>branches</th>\n",
       "      <th>branching</th>\n",
       "      <th>brands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2219 rows √ó 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      become  becomes  becoming  been  beep  began  begin  beginning  begins  \\\n",
       "0        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "1        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "3        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "4        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "5        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "6        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "7        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "8        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "9        0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "10       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "11       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "12       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "13       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "14       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "15       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "16       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "17       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "18       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "19       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "20       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "21       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "22       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "23       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "24       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "25       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "26       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "27       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "28       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "29       0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "...      ...      ...       ...   ...   ...    ...    ...        ...     ...   \n",
       "2189     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2190     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2191     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2192     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2193     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2194     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2195     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2196     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2197     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2198     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2199     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2200     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2201     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2202     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2203     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2204     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2205     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2206     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2207     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2208     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2209     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2210     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2211     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2212     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2213     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2214     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2215     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2216     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2217     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "2218     0.0      0.0       0.0   0.0   0.0    0.0    0.0        0.0     0.0   \n",
       "\n",
       "      behave   ...    boy  boyce  boyd  boys  brain  branch  branched  \\\n",
       "0        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "1        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "3        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "4        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "5        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "6        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "7        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "8        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "9        0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "10       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "11       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "12       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "13       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "14       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "15       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "16       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "17       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "18       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "19       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "20       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "21       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "22       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "23       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "24       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "25       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "26       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "27       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "28       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "29       0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "...      ...   ...    ...    ...   ...   ...    ...     ...       ...   \n",
       "2189     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2190     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2191     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2192     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2193     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2194     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2195     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2196     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2197     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2198     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2199     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2200     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2201     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2202     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2203     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2204     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2205     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2206     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2207     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2208     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2209     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2210     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2211     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2212     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2213     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2214     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2215     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2216     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2217     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "2218     0.0   ...    0.0    0.0   0.0   0.0    0.0     0.0       0.0   \n",
       "\n",
       "      branches  branching  brands  \n",
       "0          0.0        0.0     0.0  \n",
       "1          0.0        0.0     0.0  \n",
       "2          0.0        0.0     0.0  \n",
       "3          0.0        0.0     0.0  \n",
       "4          0.0        0.0     0.0  \n",
       "5          0.0        0.0     0.0  \n",
       "6          0.0        0.0     0.0  \n",
       "7          0.0        0.0     0.0  \n",
       "8          0.0        0.0     0.0  \n",
       "9          0.0        0.0     0.0  \n",
       "10         0.0        0.0     0.0  \n",
       "11         0.0        0.0     0.0  \n",
       "12         0.0        0.0     0.0  \n",
       "13         0.0        0.0     0.0  \n",
       "14         0.0        0.0     0.0  \n",
       "15         0.0        0.0     0.0  \n",
       "16         0.0        0.0     0.0  \n",
       "17         0.0        0.0     0.0  \n",
       "18         0.0        0.0     0.0  \n",
       "19         0.0        0.0     0.0  \n",
       "20         0.0        0.0     0.0  \n",
       "21         0.0        0.0     0.0  \n",
       "22         0.0        0.0     0.0  \n",
       "23         0.0        0.0     0.0  \n",
       "24         0.0        0.0     0.0  \n",
       "25         0.0        0.0     0.0  \n",
       "26         0.0        0.0     0.0  \n",
       "27         0.0        0.0     0.0  \n",
       "28         0.0        0.0     0.0  \n",
       "29         0.0        0.0     0.0  \n",
       "...        ...        ...     ...  \n",
       "2189       0.0        0.0     0.0  \n",
       "2190       0.0        0.0     0.0  \n",
       "2191       0.0        0.0     0.0  \n",
       "2192       0.0        0.0     0.0  \n",
       "2193       0.0        0.0     0.0  \n",
       "2194       0.0        0.0     0.0  \n",
       "2195       0.0        0.0     0.0  \n",
       "2196       0.0        0.0     0.0  \n",
       "2197       0.0        0.0     0.0  \n",
       "2198       0.0        0.0     0.0  \n",
       "2199       0.0        0.0     0.0  \n",
       "2200       0.0        0.0     0.0  \n",
       "2201       0.0        0.0     0.0  \n",
       "2202       0.0        0.0     0.0  \n",
       "2203       0.0        0.0     0.0  \n",
       "2204       0.0        0.0     0.0  \n",
       "2205       0.0        0.0     0.0  \n",
       "2206       0.0        0.0     0.0  \n",
       "2207       0.0        0.0     0.0  \n",
       "2208       0.0        0.0     0.0  \n",
       "2209       0.0        0.0     0.0  \n",
       "2210       0.0        0.0     0.0  \n",
       "2211       0.0        0.0     0.0  \n",
       "2212       0.0        0.0     0.0  \n",
       "2213       0.0        0.0     0.0  \n",
       "2214       0.0        0.0     0.0  \n",
       "2215       0.0        0.0     0.0  \n",
       "2216       0.0        0.0     0.0  \n",
       "2217       0.0        0.0     0.0  \n",
       "2218       0.0        0.0     0.0  \n",
       "\n",
       "[2219 rows x 100 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12) since we are working with vectors, apply the Normalizer from \n",
    "# sklearn.preprocessing to our dataframe. Print a few values \n",
    "# before and after to make sure you've applied the normalization\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "df_log[df_log.columns] = scaler.fit_transform(df_log[df_log.columns])\n",
    "df_log[df_log.columns[500:600]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:35.670049Z",
     "start_time": "2019-05-10T16:09:35.665571Z"
    }
   },
   "outputs": [],
   "source": [
    "# 13) create a function that takes a dataframe as argument and where a second\n",
    "# argument is the type of normalization (MinMaxScaler, Normalizer, StandardScaler)\n",
    "# and returns the normalized dataframe\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "\n",
    "def normalize_df(df, method='Normalizer'):\n",
    "    \n",
    "    # choose the normalization strategy\n",
    "    scaler = None\n",
    "    if method == 'Normalizer': scaler = Normalizer()\n",
    "    if method == 'MinMaxScaler': scaler = MinMaxScaler()\n",
    "    if method == 'StandardScaler': scaler = StandardScaler()\n",
    "        \n",
    "    # apply the normalization\n",
    "    if scaler != None:\n",
    "        df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "    # return the resulting dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 - Deviation Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dropbox.com/s/9f73r7pk7bi7vh9/deviation_vectors.png?dl=1\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:43.311252Z",
     "start_time": "2019-05-10T16:09:43.301099Z"
    }
   },
   "outputs": [],
   "source": [
    "# 14) compute the sum of the vectors\n",
    "v_sum = np.sum(df_log.values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:44.888477Z",
     "start_time": "2019-05-10T16:09:44.885209Z"
    }
   },
   "outputs": [],
   "source": [
    "# 15) normalize the vector (find its average)\n",
    "def vector_length(u):\n",
    "    return np.sqrt(np.dot(u, u))\n",
    "\n",
    "def length_norm(u):\n",
    "    return u / vector_length(u)\n",
    "\n",
    "v_avg = length_norm(v_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:46.003746Z",
     "start_time": "2019-05-10T16:09:45.792322Z"
    }
   },
   "outputs": [],
   "source": [
    "# 16) take each vector and subtract its components along v_avg\n",
    "\n",
    "matrix = df_log.values\n",
    "\n",
    "for row in range(df_log.shape[0]):\n",
    "\n",
    "    # this is one vector (row\n",
    "    v_i = matrix[row,:]\n",
    "\n",
    "    # we subtract its component along v_average\n",
    "    scalar = np.dot(v_i,v_avg)\n",
    "    sub = v_avg * scalar\n",
    "\n",
    "    # we replace the row by the deviation vector\n",
    "    matrix[row,:] = length_norm(v_i - sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:46.697962Z",
     "start_time": "2019-05-10T16:09:46.693198Z"
    }
   },
   "outputs": [],
   "source": [
    "# 17) put the code above in a function that takes in a dataframe as an argument\n",
    "# and computes deviation vectors of each row (=document)\n",
    "def vector_length(u):\n",
    "    return np.sqrt(np.dot(u, u))\n",
    "\n",
    "def length_norm(u):\n",
    "    return u / vector_length(u)\n",
    "\n",
    "def transform_deviation_vectors(df):\n",
    "    \n",
    "    # get the numpy matrix from the df\n",
    "    matrix = df.values\n",
    "    \n",
    "    # compute the sum of the vectors\n",
    "    v_sum = np.sum(matrix, axis=0)\n",
    "    \n",
    "    # normalize this vector (find its average)\n",
    "    v_avg = length_norm(v_sum)\n",
    "    \n",
    "    # we iterate through each vector\n",
    "    for row in range(df_log.shape[0]):\n",
    "        \n",
    "        # this is one vector (row\n",
    "        v_i = matrix[row,:]\n",
    "        \n",
    "        # we subtract its component along v_average\n",
    "        scalar = np.dot(v_i,v_avg)\n",
    "        sub = v_avg * scalar\n",
    "        \n",
    "        # we replace the row by the deviation vector\n",
    "        matrix[row,:] = length_norm(v_i - sub)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:09:47.826457Z",
     "start_time": "2019-05-10T16:09:47.610527Z"
    }
   },
   "outputs": [],
   "source": [
    "df = transform_deviation_vectors(df_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 7 - CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out how many clusters we should pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Plot the inertia of kmeans using this example from datacamp: \n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/clustering-for-dataset-exploration?ex=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:11:03.884291Z",
     "start_time": "2019-05-10T16:09:51.236928Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1a) create a list of inertia values for k 1-10\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "ks = list(range(1, 10))\n",
    "inertia = []\n",
    "\n",
    "for k in ks:   \n",
    "    km = KMeans(n_clusters=k, max_iter=1000)\n",
    "    km.fit(df.values)\n",
    "    \n",
    "    inertia.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:11:10.337608Z",
     "start_time": "2019-05-10T16:11:10.314637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0000\u0010\u0000</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0013</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0018</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0013</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0018</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0013</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018\u0000</th>\n",
       "      <th>\u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0013</th>\n",
       "      <th>...</th>\n",
       "      <th>ùëÖùëíùëêùëéùëôùëô</th>\n",
       "      <th>ùëáùêπùëñ</th>\n",
       "      <th>ùëîùëéùëñùëõ</th>\n",
       "      <th>ùëöùëíùëéùë†ùë¢ùëüùëí</th>\n",
       "      <th>ùëùùëúùë†ùë°ùë°ùëíùë†ùë°</th>\n",
       "      <th>ùëùùëüùëíùëêùëñùë†ùëñùëúùëõ</th>\n",
       "      <th>ùëùùëüùëíùë°ùëíùë†ùë°</th>\n",
       "      <th>ùëüùëíùëêùëéùëôùëô</th>\n",
       "      <th>ùë†ùëêùëúùëüùëí</th>\n",
       "      <th>ùüéùüíùüï</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.001046</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>-0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.001337</td>\n",
       "      <td>-0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>-0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000742</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 5676 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        \u0000\u0010\u0000     \u0000\u0013\u0000\u0011\u0000  \u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0013  \u0000\u0013\u0000\u0011\u0000\u0018\u0000\u0018  \u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0013  \u0000\u0013\u0000\u0011\u0000\u0019\u0000\u0018  \u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0013  \\\n",
       "0  0.000264  0.000128  0.000257  0.000257  0.000257  0.000257  0.000257   \n",
       "1  0.000354  0.000209  0.000347  0.000347  0.000347  0.000347  0.000347   \n",
       "2  0.000210  0.000094  0.000204  0.000204  0.000204  0.000204  0.000204   \n",
       "3  0.000257  0.000148  0.000251  0.000251  0.000251  0.000251  0.000251   \n",
       "4  0.000230  0.000130  0.000225  0.000225  0.000225  0.000225  0.000225   \n",
       "\n",
       "   \u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018  \u0000\u0013\u0000\u0011\u0000\u001a\u0000\u0018\u0000  \u0000\u0013\u0000\u0011\u0000\u001b\u0000\u0013    ...       ùëÖùëíùëêùëéùëôùëô       ùëáùêπùëñ      ùëîùëéùëñùëõ  \\\n",
       "0  0.000120   0.000211  0.000120    ...    -0.000039 -0.000065 -0.000566   \n",
       "1  0.000161   0.000282  0.000161    ...    -0.000010 -0.000037 -0.000577   \n",
       "2  0.000096   0.000168  0.000096    ...    -0.000040 -0.000062 -0.000489   \n",
       "3  0.000116   0.000205  0.000116    ...    -0.000011 -0.000031 -0.000433   \n",
       "4  0.000104   0.000183  0.000104    ...    -0.000013 -0.000032 -0.000401   \n",
       "\n",
       "    ùëöùëíùëéùë†ùë¢ùëüùëí  ùëùùëúùë†ùë°ùë°ùëíùë†ùë°  ùëùùëüùëíùëêùëñùë†ùëñùëúùëõ   ùëùùëüùëíùë°ùëíùë†ùë°    ùëüùëíùëêùëéùëôùëô     ùë†ùëêùëúùëüùëí       ùüéùüíùüï  \n",
       "0 -0.000039 -0.000566  -0.000066 -0.001046 -0.000066 -0.001311 -0.000195  \n",
       "1 -0.000010 -0.000577  -0.000017 -0.001068 -0.000017 -0.001337 -0.000177  \n",
       "2 -0.000040 -0.000489  -0.000068 -0.000903 -0.000068 -0.001132 -0.000173  \n",
       "3 -0.000011 -0.000433  -0.000019 -0.000802 -0.000019 -0.001005 -0.000136  \n",
       "4 -0.000013 -0.000401  -0.000022 -0.000742 -0.000022 -0.000930 -0.000127  \n",
       "\n",
       "[5 rows x 5676 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:11:25.077858Z",
     "start_time": "2019-05-10T16:11:24.988088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1b) plot the inertia values using matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(ks, inertia, 'o-')\n",
    "plt.xlabel('cluster number, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c) What can you conclude from the elbow method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Visualize your data using T-SNE\n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/visualization-with-hierarchical-clustering-and-t-sne?ex=11\n",
    "* https://www.datacamp.com/community/tutorials/introduction-t-sne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:12:40.164092Z",
     "start_time": "2019-05-10T16:11:29.182109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2a) plot the T-SNE graph using a learning rate of 200\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = TSNE(learning_rate=200)\n",
    "tsne_fit = model.fit_transform(df.values)\n",
    "\n",
    "\n",
    "xs = tsne_fit[:,0]\n",
    "ys = tsne_fit[:,1]\n",
    "\n",
    "\n",
    "plt.scatter(xs,ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b) What can you conclude from T-SNE?\n",
    "\n",
    "There are more than 10 distinct clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: T-SNE is great, but there is also some controversy on how much you should trust this algorithm:\n",
    "* [Shortcomings of T-SNE](https://stats.stackexchange.com/questions/270391/should-dimensionality-reduction-for-visualization-be-considered-a-closed-probl)\n",
    "* [Limitations of T-SNE](https://stats.stackexchange.com/questions/263539/clustering-on-the-output-of-t-sne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T16:13:44.008396Z",
     "start_time": "2019-05-10T16:13:33.951719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER 1: used, scales, topics, scores, score, osgood, semantic, topic, words, word, \n",
      "\n",
      "CLUSTER 2: parameter, solution, individualized, iafm, problem, solving, foldit, solvers, student, estimates, \n",
      "\n",
      "CLUSTER 3: using, embeddings, auto, encoder, classification, classifier, training, set, feature, data, \n",
      "\n",
      "CLUSTER 4: grade, context, matrix, threads, recommender, sequential, methods, courses, recommendation, course, \n",
      "\n",
      "CLUSTER 5: eye, gaze, text, attention, comprehension, participants, intervention, reading, wandering, mind, \n",
      "\n",
      "CLUSTER 6: clustering, measure, answers, pearson, similarities, measures, data, items, item, similarity, \n",
      "\n",
      "CLUSTER 7: students, current, prompt, learning, subgoal, srl, page, metatutor, compliance, prompts, \n",
      "\n",
      "CLUSTER 8: growth, table, game, pass, objective, level, messages, replay, math, students, \n",
      "\n",
      "CLUSTER 9: model, question, outcomes, questions, course, video, engagement, learning, learners, learner, \n",
      "\n",
      "CLUSTER 10: test, training, post, decision, full, pedagogical, policy, policies, rules, induced, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3a) apply k-means to our data with k=10 and print the first 10 words\n",
    "# that are the most associated with each cluster centroids\n",
    "# Hint: look at the cluster_centers_ of the KMeans object to find the centroids\n",
    "\n",
    "import collections\n",
    "kmeans_obj = KMeans(n_clusters=10, max_iter=1000).fit(df.values)\n",
    "\n",
    "n_words = 10\n",
    "top_words = collections.defaultdict(lambda: [])\n",
    "\n",
    "for n in range(kmeans_obj.n_clusters):\n",
    "    \n",
    "    print('CLUSTER ' + str(n+1) + ': ', end='')\n",
    "\n",
    "    indices = kmeans_obj.cluster_centers_[n].argsort()[-n_words:]\n",
    "\n",
    "    for i in indices:\n",
    "        print(vocabulary[i], end=', ')\n",
    "        top_words[n].append(vocabulary[i])\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b) interpret the cluster above; do they make sense to you?\n",
    "    1. < There is one non-word in the cluster. One of the data cleaning steps might have failed after so many different notebooks. Otherwise, the cluster appears to be concerned about topics modeling > \n",
    "    2. < Same as cluster 1, also a non-word in the cluster. This cluster appears to be about student solving problems > \n",
    "    3. etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) use hierarchical clustering on the data; feel free to refer to the datacamp lesson below: \n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/visualization-with-hierarchical-clustering-and-t-sne?ex=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T17:41:43.082836Z",
     "start_time": "2019-05-10T17:41:11.531003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4a) plot the dendogram using the link above (method = complete)\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(df.values, method='complete', )\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "dendrogram(mergings, labels=df.columns, leaf_rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b) was the dendodram useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T17:42:43.455353Z",
     "start_time": "2019-05-10T17:42:29.967999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points: 2219\n"
     ]
    }
   ],
   "source": [
    "#4c) we are going to use agglomerative clustering here \n",
    "# from the sklean library \n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "aggcluster = AgglomerativeClustering(n_clusters=10, linkage='ward').fit(df.values)\n",
    "labels = aggcluster.labels_\n",
    "\n",
    "print(\"Number of points: %i\" % labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T17:42:46.079126Z",
     "start_time": "2019-05-10T17:42:45.919732Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5676)\n"
     ]
    }
   ],
   "source": [
    "# 4d) compute the center of the cluster\n",
    "# unfortunately sklearn doesn't provide you with the centroids, but you can use the link below:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html\n",
    "\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import numpy as np\n",
    "\n",
    "clf = NearestCentroid()\n",
    "clf.fit(df.values, labels)\n",
    "\n",
    "print(clf.centroids_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T17:42:51.039820Z",
     "start_time": "2019-05-10T17:42:51.022148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTER  1 : learners, model, learning, semantic, question, questions, learner, topic, words, word, \n",
      "\n",
      "CLUSTER  2 : problems, mindset, growth, pedagogical, policy, rules, policies, induced, messages, students, \n",
      "\n",
      "CLUSTER  3 : data, work, patterns, solver, behavior, solution, problem, foldit, solving, solvers, \n",
      "\n",
      "CLUSTER  4 : context, grade, matrix, threads, recommender, sequential, methods, courses, recommendation, course, \n",
      "\n",
      "CLUSTER  5 : tasks, task, rate, component, individualized, parameter, skills, iafm, student, estimates, \n",
      "\n",
      "CLUSTER  6 : students, current, prompt, learning, subgoal, srl, page, metatutor, compliance, prompts, \n",
      "\n",
      "CLUSTER  7 : embedding, sae, training, embeddings, auto, encoder, set, classification, feature, data, \n",
      "\n",
      "CLUSTER  8 : clustering, measure, answers, pearson, similarities, measures, data, items, item, similarity, \n",
      "\n",
      "CLUSTER  9 : participants, comprehension, intervention, narrative, scientific, reading, film, text, wandering, mind, \n",
      "\n",
      "CLUSTER  10 : group, attempts, elective, math, game, students, pass, objective, level, replay, \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ['learners',\n",
       "  'model',\n",
       "  'learning',\n",
       "  'semantic',\n",
       "  'question',\n",
       "  'questions',\n",
       "  'learner',\n",
       "  'topic',\n",
       "  'words',\n",
       "  'word'],\n",
       " 1: ['problems',\n",
       "  'mindset',\n",
       "  'growth',\n",
       "  'pedagogical',\n",
       "  'policy',\n",
       "  'rules',\n",
       "  'policies',\n",
       "  'induced',\n",
       "  'messages',\n",
       "  'students'],\n",
       " 2: ['data',\n",
       "  'work',\n",
       "  'patterns',\n",
       "  'solver',\n",
       "  'behavior',\n",
       "  'solution',\n",
       "  'problem',\n",
       "  'foldit',\n",
       "  'solving',\n",
       "  'solvers'],\n",
       " 3: ['context',\n",
       "  'grade',\n",
       "  'matrix',\n",
       "  'threads',\n",
       "  'recommender',\n",
       "  'sequential',\n",
       "  'methods',\n",
       "  'courses',\n",
       "  'recommendation',\n",
       "  'course'],\n",
       " 4: ['tasks',\n",
       "  'task',\n",
       "  'rate',\n",
       "  'component',\n",
       "  'individualized',\n",
       "  'parameter',\n",
       "  'skills',\n",
       "  'iafm',\n",
       "  'student',\n",
       "  'estimates'],\n",
       " 5: ['students',\n",
       "  'current',\n",
       "  'prompt',\n",
       "  'learning',\n",
       "  'subgoal',\n",
       "  'srl',\n",
       "  'page',\n",
       "  'metatutor',\n",
       "  'compliance',\n",
       "  'prompts'],\n",
       " 6: ['embedding',\n",
       "  'sae',\n",
       "  'training',\n",
       "  'embeddings',\n",
       "  'auto',\n",
       "  'encoder',\n",
       "  'set',\n",
       "  'classification',\n",
       "  'feature',\n",
       "  'data'],\n",
       " 7: ['clustering',\n",
       "  'measure',\n",
       "  'answers',\n",
       "  'pearson',\n",
       "  'similarities',\n",
       "  'measures',\n",
       "  'data',\n",
       "  'items',\n",
       "  'item',\n",
       "  'similarity'],\n",
       " 8: ['participants',\n",
       "  'comprehension',\n",
       "  'intervention',\n",
       "  'narrative',\n",
       "  'scientific',\n",
       "  'reading',\n",
       "  'film',\n",
       "  'text',\n",
       "  'wandering',\n",
       "  'mind'],\n",
       " 9: ['group',\n",
       "  'attempts',\n",
       "  'elective',\n",
       "  'math',\n",
       "  'game',\n",
       "  'students',\n",
       "  'pass',\n",
       "  'objective',\n",
       "  'level',\n",
       "  'replay']}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4e) print the top 10 words for each cluster centroid\n",
    "\n",
    "ncluster = clf.centroids_.shape[0]\n",
    "words = {}\n",
    "vocabulary = df.columns\n",
    "for n in range(ncluster):\n",
    "    words[n] = []\n",
    "    print('CLUSTER ',(n+1),': ', end='')\n",
    "    arr = clf.centroids_[n]\n",
    "    indices = arr.argsort()[-n_words:]\n",
    "    for i in indices:\n",
    "        print(vocabulary[i], end=', '),\n",
    "        words[n].append(vocabulary[i])\n",
    "    print('\\n')\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4f) interpret the cluster above; do they make sense to you?\n",
    "1. < Cluster 1 appears to be about modeling student questions based on language analysis > \n",
    "2. < Cluster 2 appears to be policies to foster growth mindset> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBScan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Use DBscan (with epsilon=5, min_samples=10) to cluster your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T18:12:51.994663Z",
     "start_time": "2019-05-10T18:12:22.227094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2219\n"
     ]
    }
   ],
   "source": [
    "# 5a) apply DBScan on your data\n",
    "# Hint: https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=5, min_samples=10).fit(df.values)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "print(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T18:15:08.131574Z",
     "start_time": "2019-05-10T18:15:08.128260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 1\n"
     ]
    }
   ],
   "source": [
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T18:13:44.766444Z",
     "start_time": "2019-05-10T18:13:44.749121Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y has less than 2 classes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-0a2d7a372384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestCentroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroids_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y has less than 2 classes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Mask mapping each class to its members.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y has less than 2 classes"
     ]
    }
   ],
   "source": [
    "# 5b) find the cluster centroid (using the code from question 4d)\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import numpy as np\n",
    "\n",
    "clf = NearestCentroid()\n",
    "clf.fit(df.values, labels)\n",
    "\n",
    "print(clf.centroids_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T18:09:03.954280Z",
     "start_time": "2019-05-10T18:09:03.950261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.64023852e-04,  1.28034779e-04,  2.56843492e-04, ...,\n",
       "        -6.62080308e-05, -1.31122896e-03, -1.95014487e-04],\n",
       "       [ 3.54495417e-04,  2.09401839e-04,  3.47050372e-04, ...,\n",
       "        -1.74456159e-05, -1.33745068e-03, -1.77252924e-04],\n",
       "       [ 2.10236795e-04,  9.41421702e-05,  2.04061883e-04, ...,\n",
       "        -6.76016770e-05, -1.13222631e-03, -1.72903713e-04],\n",
       "       ...,\n",
       "       [-7.86482883e-05, -1.35846656e-04, -8.22314134e-05, ...,\n",
       "        -1.66470681e-04, -7.11951524e-04, -1.62334351e-04],\n",
       "       [ 1.40343428e-04,  5.26829720e-05,  1.35626277e-04, ...,\n",
       "        -6.44915504e-05, -8.70481725e-04, -1.38346085e-04],\n",
       "       [ 1.22010906e-04,  3.90904570e-05,  1.17516937e-04, ...,\n",
       "        -6.88553954e-05, -8.32499165e-04, -1.35413789e-04]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T17:39:12.686723Z",
     "start_time": "2019-05-10T17:39:12.676024Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NearestCentroid' object has no attribute 'centroids_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-4fd873d188a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 5c) print the top ten words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mncluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentroids_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NearestCentroid' object has no attribute 'centroids_'"
     ]
    }
   ],
   "source": [
    "# 5c) print the top ten words\n",
    "ncluster = clf.centroids_.shape[0]\n",
    "words = {}\n",
    "vocabulary = df.columns\n",
    "for n in range(ncluster):\n",
    "    words[n] = []\n",
    "    print('CLUSTER ',(n+1),': ', end='')\n",
    "    arr = clf.centroids_[n]\n",
    "    indices = arr.argsort()[-n_words:]\n",
    "    for i in indices:\n",
    "        print(vocabulary[i], end=', '),\n",
    "        words[n].append(vocabulary[i])\n",
    "    print('\\n')\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5d) How many clusters do you have? Do they make sense to you? Interpret them below. \n",
    "DBSCAN resulted in only one cluster, thus nearestcentroid failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Use NMF to find topics in our dataset\n",
    "* https://campus.datacamp.com/courses/unsupervised-learning-in-python/discovering-interpretable-features?ex=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T18:25:49.441317Z",
     "start_time": "2019-05-10T18:25:46.419861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08821523 0.06481561 0.14711708 0.10193784 0.06226128 0.07252723]\n",
      " [0.09148978 0.08532577 0.15242492 0.13838605 0.02947093 0.06420871]\n",
      " [0.09793506 0.12322141 0.10040113 0.15596362 0.01410963 0.08099613]\n",
      " ...\n",
      " [0.00830489 0.05107119 0.00759611 0.07538866 0.43005324 0.05735805]\n",
      " [0.02837418 0.08270261 0.0243041  0.08793025 0.32775442 0.09783094]\n",
      " [0.01348438 0.05831562 0.01930813 0.07241276 0.37608669 0.11657418]]\n"
     ]
    }
   ],
   "source": [
    "# 6a) Use the code above to apply the NMF model\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "model = NMF(n_components=6)\n",
    "\n",
    "model.fit(df.values)\n",
    "\n",
    "nmf_features = model.transform(df.values)\n",
    "\n",
    "print(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T18:27:08.653161Z",
     "start_time": "2019-05-10T18:27:08.636387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model        1.306075\n",
      "learning     1.189894\n",
      "student      1.084664\n",
      "knowledge    1.016614\n",
      "course       0.989238\n",
      "models       0.941154\n",
      "based        0.906461\n",
      "new          0.698361\n",
      "using        0.679988\n",
      "students     0.674995\n",
      "Name: 0, dtype: float64 \n",
      "\n",
      "solving     1.117260\n",
      "problem     1.037801\n",
      "foldit      0.987437\n",
      "solvers     0.951780\n",
      "behavior    0.809597\n",
      "data        0.788353\n",
      "student     0.733526\n",
      "work        0.723993\n",
      "learning    0.719932\n",
      "students    0.665839\n",
      "Name: 1, dtype: float64 \n",
      "\n",
      "students     1.362578\n",
      "table        0.822422\n",
      "scores       0.804089\n",
      "test         0.780513\n",
      "student      0.639413\n",
      "post         0.633831\n",
      "different    0.623691\n",
      "pre          0.602572\n",
      "two          0.600063\n",
      "group        0.578292\n",
      "Name: 2, dtype: float64 \n",
      "\n",
      "learning      1.148854\n",
      "students      0.914428\n",
      "prompts       0.852918\n",
      "reading       0.717632\n",
      "compliance    0.713530\n",
      "mind          0.692897\n",
      "wandering     0.664878\n",
      "related       0.621260\n",
      "metatutor     0.587052\n",
      "student       0.583212\n",
      "Name: 3, dtype: float64 \n",
      "\n",
      "data           1.146408\n",
      "feature        0.955747\n",
      "set            0.920355\n",
      "models         0.852978\n",
      "used           0.823660\n",
      "using          0.813914\n",
      "training       0.738767\n",
      "model          0.710709\n",
      "performance    0.642564\n",
      "features       0.618339\n",
      "Name: 4, dtype: float64 \n",
      "\n",
      "data            1.258051\n",
      "item            1.165106\n",
      "similarity      1.098257\n",
      "items           0.914852\n",
      "measures        0.862006\n",
      "used            0.733972\n",
      "also            0.710823\n",
      "similarities    0.704611\n",
      "answers         0.637012\n",
      "two             0.634140\n",
      "Name: 5, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6b) print the top ten words of each component\n",
    "\n",
    "# Create a DataFrame: components_df\n",
    "comp_df = pd.DataFrame(model.components_, columns=df.columns)\n",
    "\n",
    "for i in range(6):\n",
    "    component = comp_df.iloc[i,:]\n",
    "\n",
    "    print(component.nlargest(n=10), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6c) Interpret the cluster above; how do they compare to kmeans, hierarchical clustering and DBscan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 - Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Step - Putting it all together: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T15:56:08.523496Z",
     "start_time": "2019-05-10T15:55:51.097Z"
    }
   },
   "outputs": [],
   "source": [
    "# in python code, our goal is to recreate the steps above as functions\n",
    "# so that we can just one line to run topic modeling on a list of \n",
    "# documents: \n",
    "def ExtractTopicsVSM(documents, numTopics):\n",
    "    ''' this functions takes in a list of documents (strings), \n",
    "        runs topic modeling (as implemented by Sherin, 2013)\n",
    "        and returns the clustering results, the matrix used \n",
    "        for clustering a visualization '''\n",
    "    \n",
    "    # step 2: clean up the documents\n",
    "    documents = clean_list_of_documents(documents)\n",
    "    \n",
    "    # step 3: let's build the vocabulary of these docs\n",
    "    vocabulary = get_vocabulary(documents)\n",
    "    \n",
    "    # step 4: we build our list of 100-words overlapping fragments\n",
    "    documents = flatten_and_overlap(documents)\n",
    "    \n",
    "    # step 5: we convert the chunks into a matrix\n",
    "    matrix = docs_by_words_matrix(documents, vocabulary)\n",
    "    \n",
    "    # step 6: we weight the frequency of words (count = 1 + log(count))\n",
    "    matrix = one_plus_log_mat(matrix, documents, vocabulary)\n",
    "    \n",
    "    # step 7: we normalize the matrix\n",
    "    matrix = normalize(matrix)\n",
    "    \n",
    "    # step 8: we compute deviation vectors\n",
    "    matrix = transform_deviation_vectors(matrix, documents)\n",
    "    \n",
    "    # step 9: we apply a clustering algorithm to find topics\n",
    "    results_clustering = cluster_matrix(matrix)\n",
    "    \n",
    "    # step 10: we create a visualization of the topics\n",
    "    visualization = visualize_clusters(results_clustering, vocabulary)\n",
    "    \n",
    "    # finally, we return the clustering results, the matrix, and a visualization\n",
    "    return results_clustering, matrix, visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
